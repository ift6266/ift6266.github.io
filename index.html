
 <!DOCTYPE HTML>
<html lang="en-US">
<head>
  <meta charset="UTF-8">
  
    <title>Blog IFT6266 H16</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Yifan Nie">
    

    
    <meta name="description" content="Blog for IFT6266 H16">
<meta property="og:type" content="website">
<meta property="og:title" content="Blog IFT6266 H16">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Blog IFT6266 H16">
<meta property="og:description" content="Blog for IFT6266 H16">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Blog IFT6266 H16">
<meta name="twitter:description" content="Blog for IFT6266 H16">

    
    <link rel="alternative" href="/atom.xml" title="Blog IFT6266 H16" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Blog IFT6266 H16">Blog IFT6266 H16</a></h1>
				<h2 class="blog-motto">by Yifan NIE</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:yoursite.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/03/03/cats2.1/" title="Cats and Dogs 1.3 (3 Conv layer architecture) with rotated image to regularize, validation error 19.4%" itemprop="url">Cats and Dogs 1.3 (3 Conv layer architecture) with rotated image to regularize, validation error 19.4%</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Yifan Nie" target="_blank" itemprop="author">Yifan Nie</a>
		
  <p class="article-time">
    <time datetime="2016-03-03T14:24:51.000Z" itemprop="datePublished"> Published 2016-03-03</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>Hi,<br>As mentioned in Blog posts 2.01, this time, in 2.1 I tried to use a 6 layered CNN to conduct experiment, but I encountered the same strange thing as encountered by Florian. I used Adam() as update rule to do learning. During training the training error and validation error suddenly diverged and totally ruined the training process.</p>
<p>In this experiment 2.1, I still use the Random2DRotation Method to rotate each training image by a random degree, and keep their label untouched, to do regularization, so the model will learn different dogs or cats’images with different random rotated angles. I wil try to set the initial parameters for Adam() rather than using its default values.</p>
<p>In this experiment, I’m using a 6-convolution layered CNN architecture.<br>The configurations are as follows:</p>
<pre><code>num_epochs= 120 
image_shape = (256,256)
filter_sizes = [(5,5),(5,5),(5,5),(5,5),(5,5),(5,5)]
feature_maps = [20,40,60,80,100, 120]
pooling_sizes = [(2,2),(2,2),(2,2)]
mlp_hiddens = [1000]
output_size = 2
weights_init=Uniform(width=0.2)
step_rule=Adam()
max_image_dim_limit_method= MaximumImageDimension
dataset_processing = rescale to 256*256
</code></pre><p><img src="/image/cats2.1.png" alt="cats and dogs 2 result"></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2016/03/03/cats2.1/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/03/03/cats2.01/" title="Cats and Dogs 2.01 (5 Conv layer architecture) with rotatation , validation error 19.6%" itemprop="url">Cats and Dogs 2.01 (5 Conv layer architecture) with rotatation , validation error 19.6%</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Yifan Nie" target="_blank" itemprop="author">Yifan Nie</a>
		
  <p class="article-time">
    <time datetime="2016-03-03T13:24:51.000Z" itemprop="datePublished"> Published 2016-03-03</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>Hi,<br>As mentioned in Blog posts 1.3, I will try some deeper achitectures, so in this experiment 2.01 I tried to use a 5 layered CNN, and the configuration is showed as below.</p>
<p>So in order to overcome the overfitting phenomenon, there are a lot of methods to regularize, in this experiment 2.01, I still use the Random2DRotation Method to rotate each training image by a random degree, and keep their label untouched, so the model will learn different dogs or cats’images with different random rotated angles, and as we can see from the learning curve of experiment 2.01, this does help to reduce the overfitting. Globally, the training error and validation error curves are sticked together, and the validation error after 100 epochs is 19.6%. </p>
<p>In this experiment, I’m using the same 5-convolution layered CNN architecture.<br>The configurations are as follows:</p>
<pre><code>num_epochs= 100 
image_shape = (128,128)
filter_sizes = [(5,5),(5,5),(5,5),(5,5),(5,5)]
feature_maps = [20,40,60,80,100]
pooling_sizes = [(2,2),(2,2),(2,2),(2,2),(2,2)]
mlp_hiddens = [1000]
output_size = 2
weights_init=Uniform(width=0.2)
step_rule=Adam()
max_image_dim_limit_method= MaximumImageDimension
dataset_processing = rescale to 256*256
</code></pre><p><img src="/image/cats2.01.png" alt="cats and dogs 2 result"></p>
<p>But it seems a little bit strange because the validation error still stagnate at around 19.6%, should I train more epochs, or should I do other things to change the architecture, the processing of the images? </p>
<p>Next step I will try add a 6th conv layer and more feature maps at last conv layer to see if it can provide more information to the last MLP-softmax classification layer. And it might  also be worthwhile to try other data augmentation schemes to regularize.</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2016/03/03/cats2.01/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/02/28/cats1.3/" title="Cats and Dogs 1.3 (3 Conv layer architecture) with rotated image to regularize, validation error 19.4%" itemprop="url">Cats and Dogs 1.3 (3 Conv layer architecture) with rotated image to regularize, validation error 19.4%</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Yifan Nie" target="_blank" itemprop="author">Yifan Nie</a>
		
  <p class="article-time">
    <time datetime="2016-02-28T23:24:51.000Z" itemprop="datePublished"> Published 2016-02-28</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>Hi,<br>As mentioned in Blog posts 1.2, simply using the cropped image and limit their size to 128*128 doesn’t help a lot, and we can observe from experiment 1.2 that only use cropped original images to do learning will result in overfitting, and as we can observe from the learning curve in experiment 1.2, after about 700 epochs, overfitting already occurred, the valid_error will stagnate at around 27%, and the training error will continues to decrease to about 5%, but that isn’t of any use…</p>
<p>So in order to overcome the overfitting phenomenon, there are a lot of methods to regularize, in this experiment 1.3, I uses the Random2DRotation Method to rotate each training image by a random degree, and keep their label untouched, so the model will learn different dogs or cats’images with different random rotated angles, and as we can see from the learning curve of experiment 1.3, this does help to reduce the overfitting. Globally, the training error and validation error curves are sticked together, and the validation error after 100 epochs is 19.4%. </p>
<p>In this experiment, I’m using the same 3-convolution layered CNN architecture as in 1, 1.01, 1.1, 1.2<br>The configurations are as follows:</p>
<pre><code>num_epochs= 100 
image_shape = (128,128)
filter_sizes = [(5,5),(5,5),(5,5)]
feature_maps = [20,50,80]
pooling_sizes = [(2,2),(2,2),(2,2)]
mlp_hiddens = [1000]
output_size = 2
weights_init=Uniform(width=0.2)
step_rule=Adam()
max_image_dim_limit_method= MaximumImageDimension
dataset_processing = rescale to 128*128
</code></pre><p><img src="/image/cats1.3.png" alt="cats and dogs 1 result"></p>
<p>Next step I will try more complicated architectures (e.g. more layers) and with more feature maps at last conv layer to see if it can provide more information to the last MLP-softmax classification layer. And it might  also be worthwhile to try other data augmentation schemes to regularize.</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2016/02/28/cats1.3/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/02/27/cats1.2/" title="Cats and Dogs 1.2" itemprop="url">Cats and Dogs 1.2</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Yifan Nie" target="_blank" itemprop="author">Yifan Nie</a>
		
  <p class="article-time">
    <time datetime="2016-02-27T21:24:51.000Z" itemprop="datePublished"> Published 2016-02-27</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>Hi,<br>As mentioned in Blog posts 1.1, the fixed learning rate might not be a good choice, if it is chosen too small, the learning is to slow, and even cannot pull the cost function to a better minimum, on the other hand, if it is set too big, the loss will decrease and may oscillate and even bounces back to a higher loss as encountered in the figure of experiment 1.01… So Adam() might be a better choice.</p>
<p>In this experiment, I’m using the same 3-convolution layered CNN architecture as in 1 and 1.01<br>The configurations are as follows:</p>
<pre><code>num_epochs= 100 early stopped
image_shape = (128,128)
filter_sizes = [(5,5),(5,5),(5,5)]
feature_maps = [20,50,80]
pooling_sizes = [(2,2),(2,2),(2,2)]
mlp_hiddens = [1000]
output_size = 2
weights_init=Uniform(width=0.2)
step_rule=Adam()
max_image_dim_limit_method= MaximumImageDimension
dataset_processing = rescale to 128*128
</code></pre><p><img src="/image/main15.png" alt="cats and dogs 1 result"></p>
<p>This time, we can still observe the phenomenon of overfitting, so I just stopped training at epoch 21 because the valid error no longer decreases, and stagnate at around 25% however the training error still goes down. So this architecture setting might has its limitaitons. So data augmentation is very important to avoid things like overfitting. I’ll try to use rotations transformations to regularize.</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2016/02/27/cats1.2/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/02/27/cats1.1/" title="Cats and Dogs 1.1" itemprop="url">Cats and Dogs 1.1</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Yifan Nie" target="_blank" itemprop="author">Yifan Nie</a>
		
  <p class="article-time">
    <time datetime="2016-02-27T19:42:51.000Z" itemprop="datePublished"> Published 2016-02-27</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>Hi,<br>As mentioned in Blog posts 1 and 1.01, the random fixed size crop doesn’t seems to be a good way to limit the size of image to a fixed size (e.g.128*128), so inspired by Florian’s blog, I used a modified version of MinImageDimension to do MaxImageDimension to limit the size of image to a fixed size.<br>In this experiment, I’m using the same 3-convolution layered CNN architecture as in 1 and 1.01<br>The configurations are as follows:</p>
<pre><code>num_epochs= 100 early stopped
image_shape = (128,128)
filter_sizes = [(5,5),(5,5),(5,5)]
feature_maps = [20,50,80]
pooling_sizes = [(2,2),(2,2),(2,2)]
mlp_hiddens = [1000]
output_size = 2
weights_init=Uniform(width=0.2)
step_rule=Scale(learning_rate=0.05)
max_image_dim_limit_method= MaximumImageDimension
dataset_processing = rescale to 128*128
</code></pre><p><img src="/image/main14.png" alt="cats and dogs 1 result"></p>
<p>This time, we can observe the phenomenon of overfitting, so I just stopped training at epoch 27 because the valid error no longer decreases… Maybe I will try to use Adam() update rules rather than fixed learning rate, and do rotations for the images in order to reduce overfitting.</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2016/02/27/cats1.1/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/02/27/cats2/" title="Cats and Dogs 2 valid_err=19.91%" itemprop="url">Cats and Dogs 2 valid_err=19.91%</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Yifan Nie" target="_blank" itemprop="author">Yifan Nie</a>
		
  <p class="article-time">
    <time datetime="2016-02-27T19:26:51.000Z" itemprop="datePublished"> Published 2016-02-27</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>I also ran an experiment on the cluster, so I used a different architecture, So I called this experiment 2, however the image max size limiting method is still RandomFixedSizeCrop<br>In this experiment, I’m using a 3-convolution layered CNN<br>The configurations are as follows:</p>
<pre><code>num_epochs= 100 early stopped
image_shape = (128,128)
filter_sizes = [(5,5),(5,5),(5,5),(4,4),(4,4),(4,4)]
feature_maps = [20,40,60,80,100,120]
pooling_sizes = [(2,2),(2,2),(2,2),(2,2),(2,2),(2,2)]
mlp_hiddens = [1000]
output_size = 2
weights_init=Uniform(width=0.2)
step_rule=Adam()
max_image_dim_limit_method= RandomFixedSizeCrop
dataset_processing = rescale to 128*128
</code></pre><p>The result is after 100 epochs is that training error=19.57%, validation error=19.91%</p>
<h2 id="TRAINING_HAS_BEEN_FINISHED_3A"><a href="#TRAINING_HAS_BEEN_FINISHED_3A" class="headerlink" title="TRAINING HAS BEEN FINISHED:"></a>TRAINING HAS BEEN FINISHED:</h2><p>Training status:<br>batch_interrupt_received: False<br>epoch_interrupt_received: False<br>epoch_started: False<br>epochs_done: 100<br>iterations_done: 31300<br>received_first_batch: True<br>resumed_from: None<br>training_started: True<br>Log records from the iteration 31300:<br>saved_to: (‘catsVsDogs128.pkl’,)<br>time_read_data_this_epoch: 1.25491786003<br>time_read_data_total: 453.110922098<br>time_train_this_epoch: 163.532570601<br>time_train_total: 16410.0936284<br>train_cost: 0.408693790436<br>train_error_rate: 0.195686891675<br>train_total_gradient_norm: 4.36319255829<br>training_finish_requested: True<br>training_finished: True<br>valid_cost: 0.452142506838<br>valid_error_rate: 0.199169307947<br>valid_error_rate2: 0.199169307947</p>
<p>I kind of understand why the learning is kind of slow and why there’s no overfitting phenomen in 1.0 and 1.01 because I used RandomFixedSizeCrop to limit the max size of image to 128*128. This might crop the unimportant area area and label it as cats/dogs thus create some noises…<br>In next experiments, inspired by Florian’s approach, I will try to modify the MinimumImageDimension function so as to limit the maximum Image dimension.</p>
<p>The same datset pre-processing with more layers does help to boost performance, and the last convolution layer has 120 feature maps, which feeds more features to the MLP classifier.</p>
<p>In this experiment, I also used Adam() as learning rule, instead of fixed learning rate, this might also helps the performance to improve.</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2016/02/27/cats2/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/02/27/cats1.01/" title="Cats and Dogs 1.01" itemprop="url">Cats and Dogs 1.01</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Yifan Nie" target="_blank" itemprop="author">Yifan Nie</a>
		
  <p class="article-time">
    <time datetime="2016-02-27T18:04:51.000Z" itemprop="datePublished"> Published 2016-02-27</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>Hi,<br>I’ve tried another time the same configuration as in experiment 1, still with random initialization of the weights, just to add the Bokeh plotting, but the results seems to be worse than experiment 1<br>In this experiment, I’m using a 3-convolution layered CNN<br>The configurations are as follows:</p>
<pre><code>num_epochs= 100 
image_shape = (128,128)
filter_sizes = [(5,5),(5,5),(5,5)]
feature_maps = [20,50,80]
pooling_sizes = [(2,2),(2,2),(2,2)]
mlp_hiddens = [1000]
output_size = 2
weights_init=Uniform(width=0.2)
step_rule=Scale(learning_rate=0.1)
max_image_dim_limit_method= random crop
dataset_processing = rescale to 128*128
</code></pre><p>The result is after 100 epochs is that training error=35%, validation error= 35%</p>
<p><img src="/image/main11.png" alt="cats and dogs 1 result"></p>
<p>I kind of understand why the learning is kind of slow and why there’s no overfitting phenomen in 1.0 and 1.01 because I used RandomFixedSizeCrop to limit the max size of image to 128*128. This might crop the unimportant area area and label it as cats/dogs thus create some noises…<br>In next experiments, inspired by Florian’s approach, I will try to modify the MinimumImageDimension function so as to limit the maximum Image dimension.</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2016/02/27/cats1.01/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/02/26/cats1.0/" title="Cats and Dogs 1" itemprop="url">Cats and Dogs 1</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Yifan Nie" target="_blank" itemprop="author">Yifan Nie</a>
		
  <p class="article-time">
    <time datetime="2016-02-27T01:04:51.000Z" itemprop="datePublished"> Published 2016-02-26</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>Hi,<br>Just have a first try of cats and dogs project, the loading of the dataset does took me some time.<br>In this experiment, I’m using a 3-convolution layered CNN<br>The configurations are as follows:</p>
<pre><code>num_epochs= 100
image_shape = (128,128)
filter_sizes = [(5,5),(5,5),(5,5)]
feature_maps = [20,50,80]
pooling_sizes = [(2,2),(2,2),(2,2)]
mlp_hiddens = [1000]
output_size = 2
weights_init=Uniform(width=0.2)
step_rule=Scale(learning_rate=0.1)
Max_image_dim_limit_method = RandomFixedSizeCrop
Dataset_processing = rescale to 128*128
</code></pre><p>The result is after 100 epochs is that training error=26.31%, validation error= 25.77%</p>
<p>I still have some difficulty to plot the learning curves because of the Bokeh live plot problem, it always prompts me that it cannot import curstate module….</p>
<p>I tried to unpackage the pickled log file but pickle also throws error:<br>AttributeError : Unpickler instance has no attibute ‘persistent_load’. I’m trying to fix it and for the moment I have to post just a snapshot of the console snapshot.</p>
<p><img src="/image/cats1.jpg" alt="cats and dogs 1 result"></p>
<p>The learning is kind of slow, the training loss and training error decreases very slowly, I don’t know why, because the prof said using SDG will bring the loss/training error rate quickly down at first several epochs…</p>
<p>I’ll try to investigate this problem.</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2016/02/26/cats1.0/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/02/19/install_theano/" title="Installing Theano and configure the GPU" itemprop="url">Installing Theano and configure the GPU</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Yifan Nie" target="_blank" itemprop="author">Yifan Nie</a>
		
  <p class="article-time">
    <time datetime="2016-02-20T01:04:51.000Z" itemprop="datePublished"> Published 2016-02-19</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>Hello,<br>Here is a memo to show how to install the theano deep learning package on the Hades remote machine or on local machine. </p>
<p>It’s very easy to use  git to “clone” a copy of installation files onto the remote machine or on your own local machine.</p>
<p>But if you don’t have git installed on the remote machine or local machine, please first do:</p>
<pre><code>$ sudo apt-get install git-all
</code></pre><p>If you already have git installed you can do the following to clone a copy of the theano package to your machine:</p>
<pre><code>$ git clone https://github.com/Theano/Theano
</code></pre><p>This will download the theano package into your home directory</p>
<p>Then you can just install it by typing the commands:<br>Be careful, if your numpy,…ect are installed with anaconda python, you should make sure that your python command (interpreter) here is anaconda’s, and the anaconda should be installed with your user prililege not root. You can veryfy by typing from home:</p>
<pre><code>$ ls -lr
</code></pre><p>to see if the anaconda direcory’s owner is you.</p>
<p>Then cd to the Theano directory to install:</p>
<pre><code>$ cd ~/Theano
$ python setip.py develop
</code></pre><p>The installation should be fast and straightforward.</p>
<p>Then you should configure the Theano to make use of your GPU</p>
<p>You can just create a config file named .theanorc</p>
<p>to your home dir that is ~/.theanorc:</p>
<pre><code><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">[cuda]</span></span><br><span class="line"><span class="setting">root = <span class="value">/usr/local/cuda-<span class="number">7.5</span></span></span></span><br><span class="line"><span class="title">[global]</span></span><br><span class="line"><span class="setting">floatX = <span class="value">float32</span></span></span><br><span class="line"><span class="setting">device = <span class="value">gpu0</span></span></span><br><span class="line"><span class="title">[nvcc]</span></span><br><span class="line"><span class="setting">fastmath = <span class="value"><span class="keyword">True</span></span></span></span><br></pre></td></tr></table></figure>
</code></pre><p>If you don’t like to create this config file you can also create a environment variable called $CUDA_ROOT<br>    by </p>
<pre><code>$ export CUDA_ROOT = /usr/local/cuda-7.5:$CUDA_ROOT
$ source ~/.bashrc

Then you can test by login to python interpreter

$ python


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> theano</span><br></pre></td></tr></table></figure>
</code></pre><p>If the GPU is properly configured, there will be info about your GPU printed on the screen.</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2016/02/19/install_theano/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/02/15/install_anaconda_remote/" title="Installing Anaconda on the remote Hades machine" itemprop="url">Installing Anaconda on the remote Hades machine</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Yifan Nie" target="_blank" itemprop="author">Yifan Nie</a>
		
  <p class="article-time">
    <time datetime="2016-02-16T01:04:51.000Z" itemprop="datePublished"> Published 2016-02-15</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>Hello,<br>Here is a memo to show how to install anaconda (integreted package of numpy, scipy, matplotlib,…etc…) on the Hades remote machine.<br>As you know, anaconda is an integrated package containing a lot of useful packages such as numpy, matplotlib etc… so you don’t have to install them one by one. Another benefit is that we can easily install a version of MKL blas library, if installed seperately, that will cause a lot of time and may be imcompatible.</p>
<p>Because we are using the remote machine, we are only a normal user and don’t have sudo prililege. So there are several ways to install it to our user’s directory.</p>
<p>One easist way is to download the compiled anaconda installer for linux anaconda-2.5.0-x86_64.sh from the anaconda’s repo. And then upload it to the remote machine’s storage, and then install it directly on the remote machine</p>
<p><a href="https://repo.continuum.io/archive/index.html" target="_blank" rel="external">anaconda repo</a></p>
<p>You can choose a version that best suits your OS and your need (python2 or python3), download it to your local machine and then upload it to the remote machine.</p>
<p>Another easier way is to download it directly from your remote machine:</p>
<p>1.first log on to the remote machine by ssh by typing:</p>
<pre><code>$ ssh username@hades.calculquebec.ca
$ #type your password
</code></pre><ol>
<li><p>using wget command to download the anaconda package directly from your remote machine    </p>
<p> $ wget <a href="https://repo.continuum.io/archive/Anaconda2-2.5.0-Linux-x86_64.sh" target="_blank" rel="external">https://repo.continuum.io/archive/Anaconda2-2.5.0-Linux-x86_64.sh</a></p>
</li>
</ol>
<p>This command will download the installer file from the repo direcly to your remote machine.</p>
<ol>
<li><p>install the anaconda on the remote machine by executing it:</p>
<p> $ bash Anaconda2-2.5.0-Linux-x86_64.sh</p>
</li>
</ol>
<p>And then just follow the text instructions, always type yes or y to agreee with the license agreements…Then it will install, you can see the installation progress.</p>
<ol>
<li><p>update the environment variable and make that take effect immediately</p>
<p> $ source .bashrc</p>
</li>
</ol>
<p>5.And when this anaconda is installed , you’d better to install intel’s MKL Blas library, this will help better linear algebra calculations. </p>
<pre><code>$ conda install mkl
</code></pre><ol>
<li><p>Finally you can check if the MKL Blas library is correctly installed</p>
<p> $ python</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nunmpy <span class="keyword">as</span> np</span><br><span class="line">np.__config__.show()</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>If there’s something MKL in the BLAS info, you are done.</p>
<p>Trouble shooting:<br>Sometimes, with olders anaconda versions (such as 2.4.1), the MKL will give warning saying the license will expire in xxx days, actually it’s already free now. You can repair by either install anaconda 2.5.0 (newer anaconda has already fixed it) or fix older installed version by:</p>
<p>set your installation to use the mkl-linked libraries that do not require a license</p>
<pre><code>$conda remove mkl-rt
$conda install -f mkl

run conda install with the specific packages you choose or with all of Anaconda:
$conda install numpy scipy scikit-learn numexpr

or update the whole anaconda to 2.5 or newer
$conda install anaconda=2.5
</code></pre>
        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
	  	<span></span>
		<a href="/2016/02/15/install_anaconda_remote/#disqus_thread" class="comments-count-link">Comments</a>
	
</div>

</footer>


    </article>







  <nav id="page-nav" class="clearfix">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next<span></span></a>
  </nav>

</div>
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  


  

  

  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
        
          <li>
            
            	<a href="http://diro.umontreal.ca" target="_blank" title="UdeM DIRO">UdeM DIRO</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello, this is Yifan Nie&#39;s blog for IFT6266H16 <br/>
			</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2016 
		
		<a href="/about" target="_blank" title="Yifan Nie">Yifan Nie</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>










<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="Back to Top"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

<script type="text/x-mathjax-config"> 
MathJax.Hub.Config({ 
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} 
}); 
</script>
<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  </body>
 </html>
